{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment Dat Proc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chillburg/sentiment/blob/master/sentiment_Dat_Proc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3be2HMfnXwca",
        "colab_type": "text"
      },
      "source": [
        "## **Keras neural net approach**\n",
        "This approach is training a neural net on coco_val dataset and then uses it to find similarities in the sentences from the assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3zjx5UCYOs3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "4ba2fa3e-f5cd-4de3-e564-6d32a8ac873b"
      },
      "source": [
        "from time import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from nltk.corpus import stopwords\n",
        "import random\n",
        "\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers.core import Dense, Activation, Flatten\n",
        "from keras.optimizers import Adam, RMSprop, Adadelta\n",
        "from keras.utils import normalize\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
        "from keras.layers import Dropout, Conv2D, MaxPooling2D, Input, Dense, Flatten, concatenate, GlobalMaxPool2D, Lambda\n",
        "from keras.layers import GlobalAveragePooling2D, Reshape, add, LSTM, TimeDistributed\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, Lambda\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_v8lEC5X348",
        "colab_type": "text"
      },
      "source": [
        "### Step 1 - formatting coco_val data for supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBIf3DDEXvQG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "e27e2946-b8a6-4a83-e57b-ed0683945715"
      },
      "source": [
        "#corpus = pd.read_csv(\"/content/drive/My Drive/DatProc Group Assignment/coco_val.txt\", header=None)\n",
        "df_tweet = pd.read_json(\"/content/drive/My Drive/BALTA/Sentiment/tweet_corpus_edited.json\", orient=\"str\", encoding=\"ISO-8859-13\").loc[:,[\"text\",'sentiment'] ]\n",
        "print(df_tweet.shape)\n",
        "df_tweet.head"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1176, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                    text sentiment\n",
              "0     Nu gan laiks gulÄt (@ Laines mÄ«tne) http://t...       NEU\n",
              "1     Ja jau neko, nekas neizpalÄ«dz, tad jau jÄdod...       NEG\n",
              "2     es esmu tik Å”ausmÄ«gi dusmÄ«ga uz to ka savus...       NEG\n",
              "3     Å”ovakar cirks ar sotiem bija rÄcÄ«gs ;D:D di...       POZ\n",
              "4                               Ä¼oti bÄdÄ«gi palika .       NEG\n",
              "...                                                 ...       ...\n",
              "1171                                Zemgale 1:1 Kurbads       NEU\n",
              "1172  @Diaaana_B nopirki kko lÄ«dzÄ«gu Latvijas Lott...       NEU\n",
              "1173  @Santariii Tu mazias kaktuss bandas vadoni, ar...       NEU\n",
              "1174  Vai es jums esmu teikusi ka mani draugi ir paÅ...       POZ\n",
              "1175                Man uzbrÅ«k. http://t.co/gffM06Y9so       NEU\n",
              "\n",
              "[1176 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XalheBmuYYPU",
        "colab_type": "text"
      },
      "source": [
        "Removing stopwords and stemming the rest with Lancaster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5t7NNvA8l7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c74aaa94-11b9-4009-d81c-d417ce1afeaf"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "# stop_words = stopwords.words('latvian')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV9zuogLYZP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "porter = PorterStemmer()\n",
        "lancaster=LancasterStemmer()\n",
        "\n",
        "def filter_stop_words(train_sentences, stop_words):\n",
        "    for i, sentence in enumerate(train_sentences):\n",
        "        #a = enumerate(train_sentences)\n",
        "        #print(list(a))\n",
        "        #print('sentence is:', i, sentence)\n",
        "        new_sent = [lancaster.stem(word) for word in sentence.split() if word not in stop_words]\n",
        "        print(new_sent)\n",
        "        train_sentences[i] = ' '.join(new_sent)\n",
        "    return train_sentences\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "print(corpus.shape)\n",
        "print('corpus.iloc[2:10] is:\\n', corpus.iloc[:10])\n",
        "print()\n",
        "corpus_no_stops = filter_stop_words(corpus.iloc[:10, 0], stop_words)\n",
        "print('corpus_no_stops.iloc[:10]:', corpus_no_stops)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK-s3tSNYj0F",
        "colab_type": "text"
      },
      "source": [
        "Assigning groups to coco-val sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zoidl3FYo8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus.loc[0,1] = 1\n",
        "count = 0\n",
        "group = 0\n",
        "for i in range(len(corpus)):\n",
        "    #print(i)\n",
        "    if count < 5:\n",
        "        corpus.loc[i,1] = group\n",
        "        count += 1\n",
        "    else:\n",
        "        group += 1\n",
        "        corpus.loc[i,1] = group\n",
        "        count = 1\n",
        "    \n",
        "corpus.head(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5todEIWYsWR",
        "colab_type": "text"
      },
      "source": [
        "Making two columns, and nine rows for each sentence. In the second column each sentence has five correct pairs and four incorrect random pairs from the remaining corpus (further the same sentences should be removed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-vLHcA8ZC7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data = pd.DataFrame(np.zeros((100, 3)).astype(int))\n",
        "data = pd.DataFrame(np.zeros((1, 3)).astype(int))\n",
        "\n",
        "for i in range(len(corpus)):  # for each line in corpus\n",
        "    a = pd.DataFrame()\n",
        "    for j in range(9):            # 9 loops, 5 for True and 4 for False\n",
        "        a.loc[0, 0] = corpus.loc[i, 0]             # places the corpus line\n",
        "        if j < 5:                           # first five match, rest don't\n",
        "            same_gr = corpus.loc[corpus[1] == corpus.loc[i, 1]]\n",
        "            a.loc[0, 1] = same_gr.iloc[j, 0]       \n",
        "        else:                                        # if not, a random line from other groups\n",
        "            other = corpus.loc[corpus[1] != corpus.loc[i, 1]]\n",
        "            other_text = other.iloc[random.randint(0, len(other)-5)]\n",
        "            a.loc[0, 1] = other_text[0]      \n",
        "        if j < 5:\n",
        "            a.loc[0, 2] = True\n",
        "        else:\n",
        "            a.loc[0, 2] = False\n",
        "        data = pd.concat([data,a])\n",
        "data = data.iloc[1:, :]\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PYrn0RCZLwm",
        "colab_type": "text"
      },
      "source": [
        "Exporting the data as csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5baspZmZOVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "export_csv = data.to_csv('/content/drive/My Drive/DatProc Group Assignment/coco_T_F_225000_stemmed.csv', header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRG2q5TlZiGd",
        "colab_type": "text"
      },
      "source": [
        "### **Step 2 - dowloading and formatting the assignment data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9ostVWYZmXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/DatProc Group Assignment/competition_descriptions.txt') as fp:\n",
        "    corpus = fp.readlines()\n",
        "    fp.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3S2qWMKZtr2",
        "colab_type": "text"
      },
      "source": [
        "Removing special characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmlA-0pZwRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_cl = corpus\n",
        "for i in enumerate(corpus):\n",
        "    corpus_cl[i[0]] = i[1].replace(\"[comma]\", \"\").lower().replace(\".\", \"\").replace(\"\\n\", \"\").replace(\"'\", \" \").replace(\"-\", \" \").replace(\"/\", \" \").replace(\"?\", \" \").replace(\"(\", \" \").replace(\")\", \" \").strip()     #'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st4PvrKuZzcu",
        "colab_type": "text"
      },
      "source": [
        "Removing stopwords and stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB6uNWz2Z3vL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "porter = PorterStemmer()\n",
        "lancaster=LancasterStemmer()\n",
        "\n",
        "\n",
        "def filter_stop_words(train_sentences, stop_words):\n",
        "    for i, sentence in enumerate(train_sentences):\n",
        "        new_sent = [lancaster.stem(word) for word in sentence.split() if word not in stop_words]\n",
        "        train_sentences[i] = ' '.join(new_sent)\n",
        "    return train_sentences\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "corpus_cl = filter_stop_words(corpus, stop_words)\n",
        "print('corpus_cl:', corpus_cl[:10])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDulNYw8aG4i",
        "colab_type": "text"
      },
      "source": [
        "Filling a data frame with each sentence corresponding to every other sentence in the assignment data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW1LM5mEaHHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.DataFrame(np.zeros((1, 2)).astype(int))\n",
        "\n",
        "for i in range(len(corpus_cl)):  # for each line in corpus\n",
        "    print(i)\n",
        "    a = pd.DataFrame()\n",
        "    for j in range(len(corpus_cl)):\n",
        "        a.loc[0, 0] = corpus_cl[i]             # places the corpus line\n",
        "        a.loc[0, 1] = corpus_cl[j]\n",
        "        data = pd.concat([data,a])\n",
        "data = data.iloc[1:, :]\n",
        "print(data.shape)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvf0BHB-aTBc",
        "colab_type": "text"
      },
      "source": [
        "Saving the data as csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNnE5f9iaXTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.to_csv('test_set_595985.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd0icGF3fe59",
        "colab_type": "text"
      },
      "source": [
        "### **Step 3 - Training the model on coco_val grouped data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZYfL-Icf4X0",
        "colab_type": "text"
      },
      "source": [
        "Loading transformed coco_val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZH2vAqffmHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8e46392b-2b14-4175-8d13-10473bec32b8"
      },
      "source": [
        "a = pd.read_csv('/content/drive/My Drive/DatProc Group Assignment/coco_T_F_225000_stemmed.csv', dtype=str, header = None).iloc[:, 1:]\n",
        "print(a.shape)\n",
        "a.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(225000, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>child hold flow umbrell pet yak</td>\n",
              "      <td>child hold flow umbrell pet yak</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>child hold flow umbrell pet yak</td>\n",
              "      <td>young man hold umbrell next herd cattl</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>child hold flow umbrell pet yak</td>\n",
              "      <td>young boy barefoot hold umbrell touch horn cow</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>child hold flow umbrell pet yak</td>\n",
              "      <td>young boy umbrell touch horn cow</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>child hold flow umbrell pet yak</td>\n",
              "      <td>boy hold umbrell stand next livestock</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 1  ...  3\n",
              "0  child hold flow umbrell pet yak  ...  1\n",
              "1  child hold flow umbrell pet yak  ...  1\n",
              "2  child hold flow umbrell pet yak  ...  1\n",
              "3  child hold flow umbrell pet yak  ...  1\n",
              "4  child hold flow umbrell pet yak  ...  1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwtvnywjgCHD",
        "colab_type": "text"
      },
      "source": [
        "Concatenating both columns together, as this model is a single-input one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxs_l6ZKgCNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "0aeca5f9-95ac-4c08-b830-e1257077b1f4"
      },
      "source": [
        "a['space'] = ' '\n",
        "a['both'] = a[[1, 'space', 2]].apply(lambda x: ''.join(x), axis=1)\n",
        "\n",
        "print('a.shape:', a.shape)\n",
        "print('a.iloc[0, 4]:', a.iloc[0, 4])\n",
        "docs = a.iloc[:, 4]\n",
        "print('docs.shape:', docs.shape)\n",
        "print('docs.iloc[:3]:', docs.iloc[:3])\n",
        "labels = a.iloc[:, 2]\n",
        "print('labels.shape:', labels.shape)\n",
        "print('labels.iloc[:10]:', labels.iloc[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a.shape: (225000, 5)\n",
            "a.iloc[0, 4]: child hold flow umbrell pet yak child hold flow umbrell pet yak\n",
            "docs.shape: (225000,)\n",
            "docs.iloc[:3]: 0    child hold flow umbrell pet yak child hold flo...\n",
            "1    child hold flow umbrell pet yak young man hold...\n",
            "2    child hold flow umbrell pet yak young boy bare...\n",
            "Name: both, dtype: object\n",
            "labels.shape: (225000,)\n",
            "labels.iloc[:10]: 0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "5    0\n",
            "6    0\n",
            "7    0\n",
            "8    0\n",
            "9    1\n",
            "Name: 3, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xYit02EgPW4",
        "colab_type": "text"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ADsna-egR_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1292
        },
        "outputId": "73b9f067-e81b-4b05-f994-dbadfc1b9e17"
      },
      "source": [
        "vocab_size = 150\n",
        "print('vocabulary size is:', vocab_size)\n",
        "\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "print('encoded_docs:', encoded_docs[0])\n",
        "\n",
        "# pad documents to a max length of x words\n",
        "max_length = vocab_size\n",
        "\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print('padded_docs:\\n', padded_docs)\n",
        "\n",
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 128, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1024, activation = 'relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256, activation = 'relu'))\n",
        "model.add(Dropout(0.4))\n",
        "    \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer = Adam(lr = 0.000005), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summarize the model\n",
        "print(model.summary())\n",
        "\n",
        "# fit the model\n",
        "model.fit(padded_docs, labels, epochs=50, verbose=1, validation_split = 0.2, shuffle = True, batch_size = 64)\n",
        "\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocabulary size is: 150\n",
            "encoded_docs: [16, 45, 138, 60, 45, 109, 16, 45, 138, 60, 45, 109]\n",
            "padded_docs:\n",
            " [[ 16  45 138 ...   0   0   0]\n",
            " [ 16  45 138 ...   0   0   0]\n",
            " [ 16  45 138 ...   0   0   0]\n",
            " ...\n",
            " [  1 139 132 ...   0   0   0]\n",
            " [  1 139 132 ...   0   0   0]\n",
            " [  1 139 132 ...   0   0   0]]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 150, 128)          19200     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 19200)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 19200)             76800     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              19661824  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 20,041,857\n",
            "Trainable params: 20,000,897\n",
            "Non-trainable params: 40,960\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 180000 samples, validate on 45000 samples\n",
            "Epoch 1/50\n",
            " 22400/180000 [==>...........................] - ETA: 1:20 - loss: 1.0234 - acc: 0.4877"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a1c4192c4df4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV7S-jl1jzR2",
        "colab_type": "text"
      },
      "source": [
        "### **Step 4 - predict similar sentences in assignment data with the model trainded on coco_val dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk5GMLbRmkmW",
        "colab_type": "text"
      },
      "source": [
        "Downloading test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljKAfZ37kAU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1ea94c68-0664-4121-d36c-3947148eb2c1"
      },
      "source": [
        "a_test = pd.read_csv('/content/drive/My Drive/DatProc Group Assignment/test_set_595985.csv', dtype=str, header = None).iloc[1:, 1:]\n",
        "print(a_test.shape)\n",
        "print(a_test.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(595984, 2)\n",
            "                                                   1                                                  2\n",
            "1  beauty eyebrow nic hair cut complect cle young...  beauty eyebrow nic hair cut complect cle young...\n",
            "2  beauty eyebrow nic hair cut complect cle young...  short dark hair light brown ol skin thick red ...\n",
            "3  beauty eyebrow nic hair cut complect cle young...  as guy 20s short hair dark skin ton monolid ey...\n",
            "4  beauty eyebrow nic hair cut complect cle young...  person crew cut dirty blond hair squ fac round...\n",
            "5  beauty eyebrow nic hair cut complect cle young...  long hair comb emo lik beard look scraggily we...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpa7fxoxmmyB",
        "colab_type": "text"
      },
      "source": [
        "Concatenating the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA2q2_W9ldsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c19978b7-d3cd-433d-ef31-7e77a5f1154a"
      },
      "source": [
        "a_test['space'] = ' '\n",
        "a_test['both'] = a_test[[1, 'space', 2]].apply(lambda x: ''.join(x), axis=1)\n",
        "\n",
        "print('a_test.shape:', a_test.shape)\n",
        "print('a_test.iloc[0, 3]:', a_test.iloc[0, 3])\n",
        "docs_test = a_test.iloc[1:, 3]\n",
        "print('docs_test.shape:', docs_test.shape)\n",
        "print('docs_test.iloc[:3]:', docs_test.iloc[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a_test.shape: (595985, 4)\n",
            "a_test.iloc[0, 3]: 0 1\n",
            "docs_test.shape: (595984,)\n",
            "docs_test.iloc[:3]: 1    beauty eyebrow nic hair cut complect cle young...\n",
            "2    beauty eyebrow nic hair cut complect cle young...\n",
            "3    beauty eyebrow nic hair cut complect cle young...\n",
            "Name: both, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS74urwymsij",
        "colab_type": "text"
      },
      "source": [
        "Padding the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvLzNqWsmGzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "816122c3-18cc-4425-fd97-5fa30ac82531"
      },
      "source": [
        "vocab_size_test = 150\n",
        "print('vocabulary size is:', vocab_size_test)\n",
        "\n",
        "encoded_docs_test = [one_hot(d, vocab_size_test) for d in docs_test]\n",
        "print('encoded_docs_test:', encoded_docs_test[0])\n",
        "\n",
        "# pad documents to a max length of x words\n",
        "max_length_test = vocab_size_test\n",
        "\n",
        "padded_docs_test = pad_sequences(encoded_docs_test, maxlen=max_length_test, padding='post')\n",
        "print('padded_docs:\\n', padded_docs_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocabulary size is: 150\n",
            "encoded_docs_test: [87, 118, 128, 116, 3, 8, 122, 94, 143, 125, 107, 48, 142, 95, 69, 11, 130, 134, 87, 118, 128, 116, 3, 8, 122, 94, 143, 125, 107, 48, 142, 95, 69, 11, 130, 134]\n",
            "padded_docs:\n",
            " [[ 87 118 128 ...   0   0   0]\n",
            " [ 87 118 128 ...   0   0   0]\n",
            " [ 87 118 128 ...   0   0   0]\n",
            " ...\n",
            " [ 98  61  82 ...   0   0   0]\n",
            " [ 98  61  82 ...   0   0   0]\n",
            " [ 98  61  82 ...   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmhp1Mh8mvuj",
        "colab_type": "text"
      },
      "source": [
        "Predicting pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woMiwkppmjX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(padded_docs_test)\n",
        "print(predictions.shape)\n",
        "print(predictions[:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw3Ud3AT6fC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt('predictions_595985.txt', predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_9n5SiYGLp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.loadtxt('/content/predictions_595985.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ecn2rJPE_1x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "82cf8bac-1a5c-45f2-8173-e29fdfd2032b"
      },
      "source": [
        "a_united.iloc[9263, [0, 3]]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1           person black short black hair bit fac stubbl a...\n",
              "question                                                   11\n",
              "Name: 9264, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK_Ult1qtv2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "096499eb-9082-445f-b037-d6d485aae9eb"
      },
      "source": [
        "print(a_test.shape, predictions.shape)\n",
        "\n",
        "\n",
        "a_united = a_test\n",
        "a_united['predictions'] = predictions\n",
        "a_united['question'] = 0\n",
        "\n",
        "print('a_united.shape:', a_united.shape)\n",
        "print(a_united.head(2))\n",
        "\n",
        "#### crash\n",
        "for i in range(772):\n",
        "    a_united.iloc[0+i*772:772+i*772, 3] = i\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(595984, 4) (595984,)\n",
            "a_united.shape: (595984, 4)\n",
            "                                                   1  ... question\n",
            "1  beauty eyebrow nic hair cut complect cle young...  ...        0\n",
            "2  beauty eyebrow nic hair cut complect cle young...  ...        0\n",
            "\n",
            "[2 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z2zmDOQIYj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9fea7db0-c67d-4e44-e3e4-8bc974c5e252"
      },
      "source": [
        "grouped = a_united.groupby(2)['predictions']\n",
        "a_united['second_lowest'] = grouped.transform(lambda x: x.nlargest(1).max())\n",
        "print(a_united.head())\n",
        "\n",
        "np.savetxt('a_united.txt', a_united)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def find_similar_preview(line_no):\n",
        "    j = [line_no]\n",
        "    j.append(Z[line_no, :].argsort()[-2])\n",
        "    j.append(Z[line_no, :].argsort()[-3])\n",
        "    j.append(Z[line_no, :].argsort()[-4])\n",
        "    print(\"Most similar sentences to [\", line_no, \"] according to cosine similarity:\\n\", sep='')\n",
        "    print(corpus[line_no])\n",
        "    print('\\nare numbers ', j)\n",
        "    #print(corpus[j[0]])\n",
        "    print(corpus[j[1]])\n",
        "    print(corpus[j[2]])\n",
        "    print(corpus[j[3]])\n",
        "    \n",
        "\n",
        "\n",
        "def find_similar(line_no):\n",
        "    j = [line_no]\n",
        "    j.append(Z[line_no, :].argsort()[-2])\n",
        "    j.append(Z[line_no, :].argsort()[-3])\n",
        "    j.append(Z[line_no, :].argsort()[-4])\n",
        "    return j\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   1  ... second_lowest\n",
            "1  beauty eyebrow nic hair cut complect cle young...  ...      1.000000\n",
            "2  beauty eyebrow nic hair cut complect cle young...  ...      1.000000\n",
            "3  beauty eyebrow nic hair cut complect cle young...  ...      1.000000\n",
            "4  beauty eyebrow nic hair cut complect cle young...  ...      1.000000\n",
            "5  beauty eyebrow nic hair cut complect cle young...  ...      0.999995\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZvcCcNFDeEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "27741c57-46b1-4bfc-de3c-1921577faaa9"
      },
      "source": [
        "grouped = a_united.groupby(1)['predictions']\n",
        "a_united['second_lowest'] = grouped.transform(lambda x: x.nlargest(4).max())\n",
        "\n",
        "print(a_united.head(1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   1  ... second_lowest\n",
            "1  beauty eyebrow nic hair cut complect cle young...  ...      0.999999\n",
            "\n",
            "[1 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roLc-035xIQB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "03778adc-b100-4933-ad85-1b2d423334b6"
      },
      "source": [
        "print(a_test.shape)    # (595984, 3)\n",
        "print(a_test.iloc[:10, 0]) \n",
        "print('0-------------------------')\n",
        "print(a_test.iloc[:10, 1]) \n",
        "print('1-------------------------')\n",
        "print(a_test.iloc[:10, 2])\n",
        "print('2-------------------------')\n",
        "\n",
        "z = a_test.groupby(by = 1)[2].max()\n",
        "print('-------------------------')\n",
        "print(z.shape)\n",
        "print(z.head(4))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(595984, 3)\n",
            "1     beauty eyebrow nic hair cut complect cle young...\n",
            "2     beauty eyebrow nic hair cut complect cle young...\n",
            "3     beauty eyebrow nic hair cut complect cle young...\n",
            "4     beauty eyebrow nic hair cut complect cle young...\n",
            "5     beauty eyebrow nic hair cut complect cle young...\n",
            "6     beauty eyebrow nic hair cut complect cle young...\n",
            "7     beauty eyebrow nic hair cut complect cle young...\n",
            "8     beauty eyebrow nic hair cut complect cle young...\n",
            "9     beauty eyebrow nic hair cut complect cle young...\n",
            "10    beauty eyebrow nic hair cut complect cle young...\n",
            "Name: 1, dtype: object\n",
            "0-------------------------\n",
            "1     beauty eyebrow nic hair cut complect cle young...\n",
            "2     short dark hair light brown ol skin thick red ...\n",
            "3     as guy 20s short hair dark skin ton monolid ey...\n",
            "4     person crew cut dirty blond hair squ fac round...\n",
            "5     long hair comb emo lik beard look scraggily we...\n",
            "6     slight long hair wear black shirt light new kn...\n",
            "7           short stat thin build cas hair pul back mak\n",
            "8     neat high eyebrow deep set ey extrem laugh lin...\n",
            "9     person look fair look attract ey op judg perso...\n",
            "10    seem young due acn hair cut also seem lik gen ...\n",
            "Name: 2, dtype: object\n",
            "1-------------------------\n",
            "1     0.935587\n",
            "2     0.993462\n",
            "3     0.634582\n",
            "4     0.557084\n",
            "5     0.465850\n",
            "6     0.546518\n",
            "7     0.513369\n",
            "8     0.548520\n",
            "9     0.548531\n",
            "10    0.821065\n",
            "Name: predictions, dtype: float32\n",
            "2-------------------------\n",
            "3-------------------------\n",
            "-------------------------\n",
            "(771,)\n",
            "1\n",
            "14 year old dark brown hair littl past should leng approxim 5 6 height ey dark brown                     youth look whit mal long av hair fac hair slig...\n",
            "18ish year old mal long somewh unkempt brown hair acn acn scar cheek fac bit long av promin chin         youth look whit mal long av hair fac hair slig...\n",
            "20ish year old wom pul back blond hair sort round fac promin chin dimpl av siz nos blu ey round cheek    youth look whit mal long av hair fac hair slig...\n",
            "5 10 tal short straight thick dark brown hair dark ey cle shav athlet build                              youth look whit mal long av hair fac hair slig...\n",
            "Name: 2, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0b1eAA8OAoT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2652
        },
        "outputId": "c54abab2-09d8-467a-a6ec-f7d13c26d1cc"
      },
      "source": [
        "a_united.iloc[:773, 4]\n",
        "predictions[:773].sort()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02608377, 0.04240781, 0.05693784, 0.05770829, 0.05775827,\n",
              "       0.05898771, 0.06319138, 0.06597468, 0.07404107, 0.07722339,\n",
              "       0.08301091, 0.0850133 , 0.08826339, 0.08899859, 0.08943892,\n",
              "       0.09699497, 0.10174325, 0.10423276, 0.10515809, 0.10869712,\n",
              "       0.11127746, 0.11491409, 0.11844182, 0.12101236, 0.12570336,\n",
              "       0.12788451, 0.13190243, 0.13343292, 0.13867936, 0.1413084 ,\n",
              "       0.14363325, 0.14365393, 0.144151  , 0.14897257, 0.15035373,\n",
              "       0.1514931 , 0.15162063, 0.15307364, 0.15992811, 0.16416013,\n",
              "       0.16440064, 0.17778501, 0.17902544, 0.18065643, 0.18445095,\n",
              "       0.18635496, 0.18994078, 0.19239122, 0.20057392, 0.20148352,\n",
              "       0.2022633 , 0.2054989 , 0.2115517 , 0.21628767, 0.21842697,\n",
              "       0.21925154, 0.22118935, 0.2250571 , 0.22708312, 0.22718021,\n",
              "       0.22764957, 0.22851342, 0.23435557, 0.23531231, 0.2392976 ,\n",
              "       0.23984358, 0.24142399, 0.24328056, 0.24863347, 0.25113654,\n",
              "       0.25322774, 0.25746942, 0.25750586, 0.26109174, 0.26401922,\n",
              "       0.2713502 , 0.27170223, 0.27556854, 0.27856234, 0.27961487,\n",
              "       0.28197831, 0.28551847, 0.29054385, 0.29100657, 0.29201427,\n",
              "       0.29414442, 0.2947596 , 0.29994404, 0.30148408, 0.30532733,\n",
              "       0.30698138, 0.30857888, 0.31663337, 0.31842369, 0.32067209,\n",
              "       0.32853329, 0.33141333, 0.33206445, 0.3330282 , 0.33575633,\n",
              "       0.33728755, 0.34221914, 0.34765214, 0.34856048, 0.34868687,\n",
              "       0.34924537, 0.34967569, 0.35509703, 0.35571834, 0.35882616,\n",
              "       0.36319894, 0.36326379, 0.36792856, 0.36815834, 0.36847115,\n",
              "       0.37920263, 0.37941179, 0.38411132, 0.38668019, 0.38918614,\n",
              "       0.39370635, 0.39685318, 0.3999421 , 0.40236855, 0.40341729,\n",
              "       0.40438601, 0.40447527, 0.40487528, 0.40623453, 0.40758255,\n",
              "       0.40864179, 0.40907693, 0.41023284, 0.41087425, 0.41313407,\n",
              "       0.41444629, 0.41500318, 0.41674775, 0.41915113, 0.41966271,\n",
              "       0.42014813, 0.42390665, 0.42430612, 0.42555138, 0.42582393,\n",
              "       0.42768076, 0.42840609, 0.42946643, 0.42974064, 0.43014535,\n",
              "       0.43037739, 0.43042916, 0.43304858, 0.43366078, 0.43583095,\n",
              "       0.43649912, 0.43766683, 0.43845576, 0.4391408 , 0.43998674,\n",
              "       0.44045743, 0.44120103, 0.44254345, 0.44410583, 0.44480565,\n",
              "       0.44598177, 0.44605982, 0.44906309, 0.44959277, 0.45232001,\n",
              "       0.45276183, 0.45362553, 0.45493945, 0.45508349, 0.45547813,\n",
              "       0.45770121, 0.45777789, 0.45827863, 0.45869964, 0.45871103,\n",
              "       0.45957398, 0.45974669, 0.4604494 , 0.46118188, 0.46133021,\n",
              "       0.46159804, 0.46197957, 0.46394953, 0.46431103, 0.46472114,\n",
              "       0.46479073, 0.46497893, 0.46512696, 0.4658502 , 0.46616727,\n",
              "       0.46689305, 0.4671219 , 0.46713004, 0.46733832, 0.4688279 ,\n",
              "       0.46924752, 0.46959868, 0.47119397, 0.47170639, 0.47185224,\n",
              "       0.47226003, 0.47540307, 0.47729766, 0.47848967, 0.48023659,\n",
              "       0.48116308, 0.4821997 , 0.48247784, 0.48359424, 0.48367125,\n",
              "       0.48441207, 0.4846749 , 0.48483291, 0.48545375, 0.48569831,\n",
              "       0.48579499, 0.48874077, 0.49044806, 0.49099472, 0.49114543,\n",
              "       0.49277404, 0.49423587, 0.49428347, 0.49478728, 0.49479192,\n",
              "       0.49496749, 0.49662712, 0.49765143, 0.4987497 , 0.49889359,\n",
              "       0.49923864, 0.49923876, 0.49943507, 0.49944681, 0.49947557,\n",
              "       0.49997807, 0.50046086, 0.50059211, 0.50061482, 0.50110435,\n",
              "       0.50117576, 0.5020836 , 0.50263196, 0.50336128, 0.50421721,\n",
              "       0.50426477, 0.50542247, 0.50544757, 0.50593764, 0.50617611,\n",
              "       0.50653577, 0.5075314 , 0.50801009, 0.50807494, 0.50927401,\n",
              "       0.50947499, 0.50970936, 0.51012057, 0.51057738, 0.51104742,\n",
              "       0.51112634, 0.51127768, 0.51138389, 0.51289701, 0.51330703,\n",
              "       0.51336944, 0.51376659, 0.51410973, 0.51437175, 0.51490283,\n",
              "       0.51515508, 0.5152384 , 0.51535749, 0.51535749, 0.51547122,\n",
              "       0.51573515, 0.51603168, 0.5160352 , 0.51618934, 0.51621097,\n",
              "       0.51651525, 0.51670706, 0.51694268, 0.51828086, 0.51831108,\n",
              "       0.5187642 , 0.5188874 , 0.51921815, 0.51942068, 0.51946837,\n",
              "       0.51999325, 0.5200848 , 0.52024192, 0.52056456, 0.52096534,\n",
              "       0.5212549 , 0.52125943, 0.52153736, 0.52158469, 0.52186006,\n",
              "       0.52204448, 0.52260375, 0.52269328, 0.52279621, 0.52282608,\n",
              "       0.52291757, 0.52310574, 0.52319604, 0.5233714 , 0.52355981,\n",
              "       0.5236057 , 0.52365512, 0.52384371, 0.52430266, 0.52438122,\n",
              "       0.52458578, 0.52472389, 0.52475548, 0.52476186, 0.52507865,\n",
              "       0.52507889, 0.52530664, 0.52535027, 0.52549058, 0.52563828,\n",
              "       0.5257324 , 0.52574337, 0.52627021, 0.52633452, 0.5265128 ,\n",
              "       0.52678519, 0.52698684, 0.52713042, 0.5273754 , 0.52776474,\n",
              "       0.52798593, 0.52818716, 0.52854723, 0.52870595, 0.52879894,\n",
              "       0.52917749, 0.52918684, 0.52920115, 0.52927983, 0.52938497,\n",
              "       0.52956676, 0.53009379, 0.53024173, 0.53049165, 0.5306052 ,\n",
              "       0.53063679, 0.53079957, 0.53082913, 0.53095633, 0.53114682,\n",
              "       0.53117204, 0.53142554, 0.53166831, 0.53167969, 0.5320704 ,\n",
              "       0.53215307, 0.5324086 , 0.53243291, 0.53249389, 0.53250098,\n",
              "       0.53250349, 0.53277022, 0.53284562, 0.532924  , 0.53299445,\n",
              "       0.5333342 , 0.5334096 , 0.53346902, 0.53354371, 0.53361702,\n",
              "       0.53364652, 0.53370178, 0.53375185, 0.53382331, 0.53382349,\n",
              "       0.53383958, 0.53415275, 0.53468555, 0.53471899, 0.53483665,\n",
              "       0.53499049, 0.53499323, 0.53529167, 0.53535986, 0.53554529,\n",
              "       0.53564596, 0.53567314, 0.53571981, 0.53576648, 0.53578973,\n",
              "       0.53650481, 0.53676033, 0.53682017, 0.53718144, 0.53724408,\n",
              "       0.53728986, 0.53742397, 0.53742898, 0.5379293 , 0.53797007,\n",
              "       0.53855634, 0.53865224, 0.53871232, 0.53901064, 0.53968501,\n",
              "       0.54025066, 0.54044843, 0.54051059, 0.54078132, 0.54118627,\n",
              "       0.54124796, 0.54133189, 0.54135543, 0.54141116, 0.54141754,\n",
              "       0.54147416, 0.54156399, 0.54166818, 0.54189068, 0.54196769,\n",
              "       0.54218596, 0.54220963, 0.54221392, 0.54226869, 0.54234982,\n",
              "       0.54271305, 0.54279822, 0.54316056, 0.54316473, 0.54346985,\n",
              "       0.54347557, 0.54381889, 0.54386216, 0.54407948, 0.54416835,\n",
              "       0.54439002, 0.54464662, 0.54491729, 0.54496229, 0.54547775,\n",
              "       0.54580444, 0.54589653, 0.54651809, 0.546839  , 0.54695958,\n",
              "       0.54712284, 0.547162  , 0.54721725, 0.54726321, 0.5476265 ,\n",
              "       0.54776514, 0.54777086, 0.54789448, 0.54814517, 0.54819882,\n",
              "       0.54851991, 0.54853088, 0.54860437, 0.54868722, 0.54885185,\n",
              "       0.54886848, 0.5489074 , 0.54922539, 0.54929686, 0.54939425,\n",
              "       0.54942256, 0.54966074, 0.54967815, 0.54994583, 0.54996449,\n",
              "       0.55066395, 0.5506708 , 0.55111134, 0.55169809, 0.55209082,\n",
              "       0.55215192, 0.55301368, 0.55304408, 0.55310148, 0.5542118 ,\n",
              "       0.55432528, 0.55468458, 0.55470973, 0.55487835, 0.55536222,\n",
              "       0.55544853, 0.55546826, 0.55585265, 0.55591518, 0.55649889,\n",
              "       0.5569784 , 0.55700058, 0.5570842 , 0.55723643, 0.55789876,\n",
              "       0.55850732, 0.55868113, 0.55908507, 0.55925983, 0.55938375,\n",
              "       0.55955362, 0.56006962, 0.56036592, 0.56042433, 0.56184709,\n",
              "       0.56234455, 0.56265104, 0.56270218, 0.56285453, 0.56324112,\n",
              "       0.56332368, 0.56376028, 0.56399053, 0.56414574, 0.5643515 ,\n",
              "       0.56435525, 0.5647465 , 0.56476927, 0.56490576, 0.56509674,\n",
              "       0.5652231 , 0.56589013, 0.56600004, 0.56614059, 0.56625408,\n",
              "       0.56659359, 0.56669343, 0.56706142, 0.56793296, 0.56859928,\n",
              "       0.56861579, 0.56862539, 0.56914932, 0.56926703, 0.56976634,\n",
              "       0.56997359, 0.57064587, 0.57065284, 0.57098591, 0.57142133,\n",
              "       0.57144153, 0.57148361, 0.57197666, 0.57311666, 0.57316196,\n",
              "       0.57321662, 0.57390052, 0.57414246, 0.57566631, 0.57592177,\n",
              "       0.57692766, 0.57730162, 0.57784176, 0.5790444 , 0.57905781,\n",
              "       0.57913041, 0.57918048, 0.57960439, 0.58000696, 0.58053845,\n",
              "       0.58137113, 0.58146781, 0.58190256, 0.58360946, 0.58378291,\n",
              "       0.58429933, 0.58493567, 0.58516872, 0.58531344, 0.58636951,\n",
              "       0.58696532, 0.5870074 , 0.58775175, 0.58778447, 0.58844739,\n",
              "       0.58891672, 0.58944404, 0.59032065, 0.59036213, 0.59041572,\n",
              "       0.59067041, 0.59211713, 0.59261012, 0.59313977, 0.59379309,\n",
              "       0.59380436, 0.59415114, 0.59452295, 0.59452736, 0.59669083,\n",
              "       0.59712493, 0.59731221, 0.5975278 , 0.59810889, 0.59972548,\n",
              "       0.60075849, 0.60077345, 0.60401791, 0.60650414, 0.6073004 ,\n",
              "       0.61187768, 0.61211979, 0.61218548, 0.61427927, 0.61432844,\n",
              "       0.61479592, 0.61493111, 0.6152668 , 0.61888814, 0.61905134,\n",
              "       0.6195274 , 0.61974365, 0.62021422, 0.62154585, 0.62203026,\n",
              "       0.62244004, 0.62324977, 0.62605846, 0.6263684 , 0.62716269,\n",
              "       0.62744415, 0.62859112, 0.63101387, 0.63386869, 0.63458222,\n",
              "       0.63468277, 0.63502878, 0.63765866, 0.63946491, 0.6444639 ,\n",
              "       0.64475465, 0.64540052, 0.64830554, 0.64882791, 0.64985561,\n",
              "       0.65056682, 0.65109986, 0.65188998, 0.65343922, 0.6534453 ,\n",
              "       0.65422559, 0.65424639, 0.65461063, 0.65568733, 0.65647274,\n",
              "       0.65815336, 0.65829182, 0.65865326, 0.65959579, 0.65960443,\n",
              "       0.66033912, 0.66072279, 0.66141158, 0.66352296, 0.66386199,\n",
              "       0.66473269, 0.66580516, 0.66600144, 0.66713464, 0.66723889,\n",
              "       0.66853797, 0.67323518, 0.67380702, 0.67922968, 0.68238252,\n",
              "       0.68276119, 0.68361139, 0.68534166, 0.68832827, 0.68910718,\n",
              "       0.69097137, 0.69154489, 0.69279391, 0.71845609, 0.72081167,\n",
              "       0.7275157 , 0.73126119, 0.73502147, 0.73649096, 0.73702002,\n",
              "       0.73837793, 0.74387288, 0.74562538, 0.74880654, 0.75001925,\n",
              "       0.75381279, 0.75510538, 0.75777155, 0.76092362, 0.76336169,\n",
              "       0.76619267, 0.76710045, 0.76792377, 0.77622926, 0.7886762 ,\n",
              "       0.79614621, 0.79652047, 0.7998091 , 0.80218077, 0.80944002,\n",
              "       0.82106495, 0.82706106, 0.82860059, 0.83270764, 0.85068119,\n",
              "       0.86574709, 0.86985689, 0.87051761, 0.87065297, 0.87447906,\n",
              "       0.87774146, 0.87798846, 0.88010347, 0.88417089, 0.89176869,\n",
              "       0.8959679 , 0.89966196, 0.90054321, 0.91289198, 0.91777998,\n",
              "       0.92966139, 0.92988932, 0.93558693, 0.9356643 , 0.93659759,\n",
              "       0.95118231, 0.95269418, 0.95656037, 0.96150744, 0.96406782,\n",
              "       0.96491593, 0.96761119, 0.97138971, 0.97390056, 0.97691184,\n",
              "       0.9929859 , 0.99346161, 0.99441248, 0.99446487, 0.99460077,\n",
              "       0.99475724, 0.99547458, 0.99592316, 0.99604613, 0.99667597,\n",
              "       0.99692374, 0.99733019, 0.99758387, 0.99791944, 0.99818921,\n",
              "       0.99900639, 0.99935293, 0.99959254, 0.99960244, 0.9996264 ,\n",
              "       0.99969816, 0.99973583, 0.9997772 , 0.99986649, 0.99995583,\n",
              "       0.99995691, 0.99998939, 0.99999899])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}